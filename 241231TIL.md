import streamlit as st
import openai
import requests
from bs4 import BeautifulSoup
import pyperclip
import re
import os

# OpenAI API ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')

# ì„¸ì…˜ ì´ˆê¸°í™”
if 'introduction' not in st.session_state:
    st.session_state.introduction = None
if 'generated_content' not in st.session_state:
    st.session_state.generated_content = []
if 'references' not in st.session_state:
    st.session_state.references = []
if 'form_data' not in st.session_state:
    st.session_state.form_data = {
        'keyword': '',
        'target': '',
        'problem': '',
        'business_name': '',
        'expertise': '',
        'additional_words': ''
    }
if 'recommended_titles' not in st.session_state:
    st.session_state.recommended_titles = []
if 'content_generated' not in st.session_state:
    st.session_state.content_generated = False
if 'show_references' not in st.session_state:
    st.session_state.show_references = False

# í‚¤ì›Œë“œ í˜•íƒœì†Œ ë¶„ë¦¬
def split_keyword_into_morphemes(keyword):
    return re.split(r"[,\s\-]+", keyword)

# í‚¤ì›Œë“œ ì‚¬ìš© íšŸìˆ˜ ì œí•œ
def limit_keyword_usage(text, keywords, max_count=20):
    for keyword in keywords:
        matches = list(re.finditer(fr"\b{re.escape(keyword)}\b", text, re.IGNORECASE))
        if len(matches) > max_count:
            for match in matches[max_count:]:
                text = text[:match.start()] + text[match.end():]
    return text

# ì¶”ê°€ ë‹¨ì–´ ì‚½ì…
def insert_additional_words(text, additional_words):
    for word in additional_words:
        if word not in text:
            text += f" {word}"
    return text

# RAG ê¸°ë°˜ ì •ëŸ‰ ìë£Œ ê²€ìƒ‰
def fetch_quantitative_data(section_title, keyword):
    references = []
    try:
        query = f"{keyword} {section_title}"
        search_url = f"https://search.naver.com/search.naver?query={query}&where=news"
        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(response.text, 'html.parser')
        for item in soup.select('.news_area')[:2]:
            title_elem = item.select_one('.news_tit')
            if title_elem:
                references.append({
                    'title': title_elem.get('title', '').strip(),
                    'url': title_elem['href'],
                    'source': 'ë„¤ì´ë²„ ë‰´ìŠ¤'
                })
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
    return references

# ì„œë¡  ìƒì„±
def generate_introduction(keyword, target, problem, expertise):
    try:
        prompt = f"""
        ì£¼ì œ í‚¤ì›Œë“œ: {keyword}
        ëª©í‘œ ë…ì: {target}
        ë…ìì˜ ê³ ë¯¼: {problem}
        ì—…ì²´ ì „ë¬¸ì„±: {expertise}

        ì„œë¡  ì‘ì„± ê·œì¹™:
        1. ë…ìê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ì œì‹œí•˜ì„¸ìš”.
        2. í•´ê²°ì±…ì„ ì œì•ˆí•˜ë©° ì „ë¬¸ì„±ì„ ê°•ì¡°í•˜ì„¸ìš”.
        3. 300ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ì„œë¡  ì‘ì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        introduction = response.choices[0].message.content
        keywords = split_keyword_into_morphemes(keyword)
        additional_words = st.session_state.form_data.get('additional_words', '').split()
        introduction = limit_keyword_usage(introduction, keywords)
        return insert_additional_words(introduction, additional_words)
    except Exception as e:
        st.error(f"ì„œë¡  ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return st.session_state.introduction  # ê¸°ì¡´ ë°ì´í„° ìœ ì§€

# ë³¸ë¬¸ ìƒì„±
def generate_section_content(section_title, keyword):
    try:
        prompt = f"""
        ì£¼ì œ í‚¤ì›Œë“œ: {keyword}
        ì†Œì œëª©: {section_title}

        ì‘ì„± ê·œì¹™:
        1. ë…ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
        2. ì •ëŸ‰ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì´ì„¸ìš”.
        3. 400ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë³¸ë¬¸ ì‘ì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=700
        )
        content = response.choices[0].message.content
        keywords = split_keyword_into_morphemes(keyword)
        additional_words = st.session_state.form_data.get('additional_words', '').split()
        content = limit_keyword_usage(content, keywords)
        return insert_additional_words(content, additional_words)
    except Exception as e:
        st.error(f"ë³¸ë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

# ê²°ë¡  ìƒì„±
def generate_conclusion(business_name, expertise):
    try:
        prompt = f"""
        ì—…ì²´ëª…: {business_name}
        ì „ë¬¸ì„±: {expertise}

        ê²°ë¡  ì‘ì„± ê·œì¹™:
        1. ìœ„ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”.
        2. ì„œë¹„ìŠ¤ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆë„ë¡ ê°•ì¡°í•˜ì„¸ìš”.
        3. 200ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ê²°ë¡  ì‘ì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=300
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ê²°ë¡  ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

# í´ë¦½ë³´ë“œ ë³µì‚¬ í•¨ìˆ˜
def copy_to_clipboard():
    try:
        # ì„œë¡ ê³¼ ë³¸ë¬¸, ê²°ë¡  ê²°í•©
        full_text = (
            f"## ì„œë¡ \n\n{st.session_state.introduction}\n\n"
            f"## ë³¸ë¬¸\n\n"
            + "\n\n".join(
                f"### {title}\n\n{content or 'ë¬¸ë‹¨ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ.'}"
                for title, content in zip(
                    st.session_state.recommended_titles, st.session_state.generated_content
                )
            )
            + f"\n\n## ê²°ë¡ \n\n{generate_conclusion(st.session_state.form_data['business_name'], st.session_state.form_data['expertise'])}"
        )
        pyperclip.copy(full_text)  # í´ë¦½ë³´ë“œì— í…ìŠ¤íŠ¸ ë³µì‚¬
        st.toast("âœ… ê¸€ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"í´ë¦½ë³´ë“œ ë³µì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ì°¸ê³ ìë£Œ ë³´ê¸°
def display_references():
    st.subheader("ğŸ“š ì°¸ê³ ìë£Œ")
    if st.session_state.references:
        for ref in st.session_state.references:
            st.markdown(f"- [{ref['title']}]({ref['url']}) ({ref['source']})")
    else:
        st.info("ì°¸ê³ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("ë¸”ë¡œê·¸ì¹˜íŠ¸í‚¤ v3")

    # ì…ë ¥ í¼
    with st.form(key='input_form'):
        st.subheader("ğŸ“Œ í‚¤ì›Œë“œì™€ ë…ì ì„¤ì •")
        keyword = st.text_input("ì£¼ì œ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ë‹¤ì´ì–´íŠ¸, ì¬í…Œí¬ ë“±")
        target = st.text_input("ëª©í‘œ ë…ì", placeholder="ì˜ˆ: 30ëŒ€ ì§ì¥ì¸")
        problem = st.text_input("ë…ìì˜ ê³ ë¯¼/ë‹ˆì¦ˆ", placeholder="ì˜ˆ: ì‹œê°„ ë¶€ì¡±")
        business_name = st.text_input("ì—…ì²´ëª…", placeholder="ì˜ˆ: OOO ì„œë¹„ìŠ¤")
        expertise = st.text_input("ì—…ì²´ ì „ë¬¸ì„±", placeholder="ì˜ˆ: 10ë…„ ê²½ë ¥ê³¼ ê³ ê° ë§Œì¡±ë„ 1ìœ„")
        additional_words = st.text_input("ì¶”ê°€ ë‹¨ì–´ (ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: ì¶”ì²œ, ë¬´ë£Œ, ì¸ê¸°")
        submit = st.form_submit_button("ì†Œì œëª© ì¶”ì²œ")
        if submit:
            st.session_state.form_data = {
                'keyword': keyword,
                'target': target,
                'problem': problem,
                'business_name': business_name,
                'expertise': expertise,
                'additional_words': additional_words
            }
            st.session_state.recommended_titles = [f"{keyword}ë€ ë¬´ì—‡ì¸ê°€?", f"{keyword}ì˜ ì¥ì ", f"{keyword} ì‚¬ìš© ë°©ë²•"]

    # ê¸€ ìƒì„±
    if st.session_state.recommended_titles:
        st.subheader("ì¶”ì²œëœ ì†Œì œëª©")
        for idx, title in enumerate(st.session_state.recommended_titles, start=1):
            st.markdown(f"{idx}. {title}")

        if st.button("ê¸€ ìƒì„± ì‹œì‘"):
            with st.spinner("ê¸€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.introduction = generate_introduction(
                    st.session_state.form_data['keyword'],
                    st.session_state.form_data['target'],
                    st.session_state.form_data['problem'],
                    st.session_state.form_data['expertise']
                )
                st.session_state.generated_content = [
                    generate_section_content(title, st.session_state.form_data['keyword'])
                    for title in st.session_state.recommended_titles
                ]
                st.session_state.content_generated = True

    # ìƒì„±ëœ ê¸€ í‘œì‹œ
    if st.session_state.content_generated:
        st.subheader("## ì„œë¡ ")
        st.markdown(st.session_state.introduction)

        st.subheader("## ë³¸ë¬¸")
        for idx, content in enumerate(st.session_state.generated_content, start=1):
            st.markdown(f"### {st.session_state.recommended_titles[idx-1]}")
            st.markdown(content or "ë¬¸ë‹¨ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ.")

            col1, col2 = st.columns(2)
            with col1:
                if st.button(f"ë‹¤ì‹œì“°ê¸° ({idx})", key=f"rewrite_{idx}"):
                    updated_text = generate_section_content(
                        st.session_state.recommended_titles[idx-1],
                        st.session_state.form_data['keyword']
                    )
                    if updated_text:
                        st.session_state.generated_content[idx-1] = updated_text
            with col2:
                if st.button(f"ì •ëŸ‰ ìë£Œ ì¶”ê°€ ({idx})", key=f"add_ref_{idx}"):
                    references = fetch_quantitative_data(
                        st.session_state.recommended_titles[idx-1],
                        st.session_state.form_data['keyword']
                    )
                    if references:
                        st.session_state.references.extend(references)

        st.subheader("## ê²°ë¡ ")
        st.markdown(generate_conclusion(
            st.session_state.form_data['business_name'],
            st.session_state.form_data['expertise']
        ))

        # í•˜ë‹¨ ì‘ì—… ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ“‹ ë³µì‚¬í•˜ê¸°"):
                copy_to_clipboard()
        with col2:
            if st.button("ğŸ“š ì°¸ê³ ìë£Œ ë³´ê¸°"):
                st.session_state.show_references = True
        with col3:
            if st.button("ğŸ”„ ë‹¤ì‹œì“°ê¸° (ëª¨ë‘ ì´ˆê¸°í™”)"):
                st.session_state.content_generated = False
                st.session_state.generated_content = []
                st.session_state.introduction = None
                st.session_state.references = []

    # ì°¸ê³ ìë£Œ í‘œì‹œ (ë§¨ í•˜ë‹¨)
    if st.session_state.show_references:
        display_references()

if __name__ == "__main__":
    main()