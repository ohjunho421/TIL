# Auto-CoT 논문의 실험방법 및 결과 요약

## 1. 실험 설정

### 1.1 사용한 데이터셋
10개의 벤치마크 데이터셋을 사용하여 실험을 진행했으며, 이는 세 가지 범주로 분류됩니다:

- **산술 추론 (Arithmetic Reasoning)**:
  - MultiArith, GSM8K, AddSub, AQuA-RAT, SingleEq, SVAMP
- **상식 추론 (Commonsense Reasoning)**:
  - CSQA, StrategyQA
- **기호적 추론 (Symbolic Reasoning)**:
  - Last Letter Concatenation, Coin Flip

### 1.2 비교 기준 (Baseline Models)
Auto-CoT의 성능을 다음 4가지 모델과 비교했습니다:
1. **Zero-Shot**:
   - 질문에 대해 바로 답을 생성하는 방식.
2. **Zero-Shot-CoT**:
   - 질문 후 "Let's think step by step" 프롬프트를 추가해 중간 단계를 생성.
3. **Few-Shot**:
   - 몇 가지 예제 질문과 답변을 추가하여 학습.
4. **Manual-CoT**:
   - 사람이 직접 설계한 단계별 시연 예제를 사용.

### 1.3 사용 모델
- **GPT-3 (text-davinci-002)**:
  - 파라미터 수: 175B.
- 일부 실험에서 **Codex (code-davinci-002)** 모델도 테스트.

### 1.4 Auto-CoT의 구성
Auto-CoT는 다음 단계를 통해 시연 예제를 생성합니다:
1. **질문 클러스터링**:
   - Sentence-BERT를 사용해 질문을 임베딩하고 K-means로 클러스터링.
2. **예제 생성**:
   - 각 클러스터에서 대표 질문을 선택하고 Zero-Shot-CoT를 사용해 단계별 풀이 생성.
3. **선택 기준**:
   - 질문은 60단어 이하, 풀이 단계는 5단계 이하인 예제만 사용.

---

## 2. 실험 결과

### 2.1 전반적인 성능 비교
다음 표는 Auto-CoT가 다른 모델들과 비교한 정확도(%)를 보여줍니다:

| **모델**            | **Arithmetic** | **Commonsense** | **Symbolic** |
|---------------------|---------------|-----------------|--------------|
| **Zero-Shot**       | 낮음 (~22.7)   | 보통 (~72.6)     | 낮음 (~53.8) |
| **Zero-Shot-CoT**   | 중간 (~78.7)   | 중간 (~64.6)     | 높음 (~91.4) |
| **Few-Shot**        | 낮음 (~33.8)   | 높음 (~79.5)     | 낮음 (~57.2) |
| **Manual-CoT**      | 높음 (~91.7)   | 높음 (~73.5)     | 높음 (~97.2) |
| **Auto-CoT**        | **높음 (~92.0)**| **높음 (~74.4)** | **매우 높음 (~99.9)** |

### 2.2 주요 결과
1. **Manual-CoT와 비교**:
   - Auto-CoT는 대부분의 데이터셋에서 Manual-CoT와 비슷하거나 더 나은 성능을 보임.
2. **Zero-Shot-CoT와 비교**:
   - Auto-CoT는 Zero-Shot-CoT보다 더 안정적이고 높은 정확도를 보임.
3. **Codex 모델 사용**:
   - Auto-CoT는 Codex 모델에서도 뛰어난 성능을 유지하며 일반적으로 더 효율적.

---

### 2.3 질문 다양성의 중요성
- Auto-CoT는 질문의 **다양성**을 고려하여 구성된 예제를 사용해 성능을 개선.
- 유사한 질문을 반복 사용하는 대신, 다양한 클러스터에서 샘플링하여 오류 전파를 방지.

---

### 2.4 스트리밍 환경에서의 성능
Auto-CoT는 데이터가 배치(batch) 단위로 실시간 스트리밍 형태로 도착할 때도 높은 성능을 유지:
- **초기 배치**:
  - Zero-Shot-CoT와 동일한 성능.
- **이후 배치**:
  - Manual-CoT 수준의 성능을 달성.

---

## 3. 시사점
1. **자동화의 효율성**:
   - 사람이 직접 설계한 예제 없이도 Manual-CoT 수준의 성능을 달성.
2. **범용성**:
   - 다양한 데이터셋에서 일관된 성능을 보이며 다른 모델(Codex)에서도 효과적.

---

Auto-CoT는 사람이 설계한 프롬프트 없이도 자동으로 CoT를 구현할 수 있다는 점에서 매우 유용하며, 다양한 데이터셋과 환경에서 적용 가능성이 높음을 보여줍니다.